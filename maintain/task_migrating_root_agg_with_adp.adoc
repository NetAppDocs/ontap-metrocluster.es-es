---
permalink: maintain/task_migrating_root_agg_with_adp.html 
sidebar: sidebar 
keywords: metrocluster, maintain, service, migrate, root, aggregate, adp, disks, partition, advanced, disk, partitioning 
summary: 'Puede migrar un agregado raíz existente de forma no disruptiva mediante la creación avanzada de particiones de discos (ADP).' 
---
= Migrar un agregado raíz configurado con ADP en configuraciones IP de MetroCluster
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


Es posible migrar de forma no disruptiva un agregado raíz existente que utilice la creación avanzada de particiones de disco (ADP) si el agregado raíz se está quedando sin espacio o si desea cambiar de uso de SSD de baja capacidad a SSD de gran capacidad.

.Acerca de esta tarea
* El par de alta disponibilidad (HA) local debe estar habilitado para la conmutación por error del almacenamiento.
* Este procedimiento no es disruptivo.
* La configuración debe estar en estado constante y sirviendo datos con normalidad, sin interrupciones frecuentes.
* Durante este procedimiento, no realice ninguna actualización de hardware ni ninguna otra operación que pueda provocar interrupción.
* Solo puede migrar un agregado raíz a la vez. No intente migrar dos agregados raíz al mismo tiempo.


.Pasos
. [[STEP_1, verifique el estado de la configuración]]Compruebe el estado de la configuración.
+
.. Compruebe que la MetroCluster esté configurada y en modo normal de cada clúster:
 +
`metrocluster show`
+
[listing]
----
cluster_A::> metrocluster show
Cluster                   Entry Name          State
------------------------- ------------------- -----------
 Local: cluster_A         Configuration state configured
                          Mode                normal
                          AUSO Failure Domain auso-on-cluster-disaster
Remote: cluster_B         Configuration state configured
                          Mode                normal
                          AUSO Failure Domain auso-on-cluster-disaster
----
.. Compruebe que el mirroring está habilitado en cada nodo:
+
`metrocluster node show`

+
[listing]
----
cluster_A::> metrocluster node show
DR                           Configuration  DR
Group Cluster Node           State          Mirroring Mode
----- ------- -------------- -------------- --------- --------
1     cluster_A
              node_A_1       configured     enabled   normal
      cluster_B
              node_B_1       configured     enabled   normal
2 entries were displayed.
----
.. Compruebe que los componentes de MetroCluster sean los mismos en buen estado:
+
`metrocluster check run`

+
[listing]
----
cluster_A::> metrocluster check run

Last Checked On: 10/1/2014 16:03:37

Component           Result
------------------- ---------
nodes               ok
lifs                ok
config-replication  ok
aggregates          ok
4 entries were displayed.

Command completed. Use the "metrocluster check show -instance" command or sub-commands in "metrocluster check" directory for detailed results.
To check if the nodes are ready to do a switchover or switchback operation, run "metrocluster switchover -simulate" or "metrocluster switchback -simulate", respectively.
----
.. Compruebe que no hay alertas de estado:
+
`system health alert show`



. Confirme que el par de alta disponibilidad local está habilitado para la conmutación por error del almacenamiento:
+
`storage failover show`

+
La salida debe indicar que la toma de control es posible para ambos nodos:

+
[listing]
----
cluster_A::> storage failover show
                              Takeover
Node           Partner        Possible State Description
-------------- -------------- -------- ---------------------------
cluster-01     cluster-02      true     Connected to cluster-02

cluster-02     cluster-01      true     Connected to cluster-01
2 entries were displayed.
----
. Ponga a cero los discos de repuesto:
+
`run * disk zero spares`

. Identifique el tamaño del agregado raíz:
+
`node run local aggr status -r <root_agg_name>`

+
En el ejemplo siguiente, el agregado raíz tiene diez discos en «Pool0» y diez en «Pool1».

+
[listing]
----
cluster_A::*> node run local aggr status -r <root_agg_name>
Aggregate <root_agg_name> (online, raid_dp, mirrored, fast zeroed) (block checksums)
  Plex /<root_agg_name>/plex0 (online, normal, active, pool0)
    RAID group /<root_agg_name>/plex0/rg0 (normal, block checksums, max_wdbn 5767167)

      RAID Disk Device  HA  SHELF BAY CHAN Pool Type  RPM  Used (MB/blks)    Phys (MB/blks)
      --------- ------  ------------- ---- ---- ---- ----- --------------    --------------
      dparity   e2a.11.0.0P3    e2a   11  0   NV:A   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      parity    e10b.11.3.1P3   e10b  11  1   NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e2a.11.0.2P3    e2a   11  2   NV:A   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e2a.11.0.3P3    e2a   11  3   NV:A   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e2a.11.0.4P3    e2a   11  4   NV:A   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.5P3   e10b  11  5   NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.12P3  e10b  11  12  NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.13P3  e10b  11  13  NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.14P3  e10b  11  14  NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.15P3  e10b  11  15  NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)

  Plex /<root_agg_name>/plex2 (online, normal, active, pool1)
    RAID group /<root_agg_name>/plex2/rg0 (normal, block checksums, max_wdbn 5767167)

      RAID Disk Device  HA  SHELF BAY CHAN Pool Type  RPM  Used (MB/blks)    Phys (MB/blks)
      --------- ------  ------------- ---- ---- ---- ----- --------------    --------------
      dparity   0m.i2.2L1P3     0m    22  5          1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      parity    0m.i1.0L36P3    0m    22  14         1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0v.i2.2L18P3    0v    22  12         1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0v.i2.3L17P3    0v    22  2          1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0v.i1.0L25P3    0v    22  13         1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0v.i1.0L40P3    0v    22  4          1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0m.i1.1L39P3    0m    22  17         1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0m.i1.1L46P3    0m    22  15         1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0m.i2.3L13P3    0m    22  0          1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0v.i1.1L26P3    0v    22  1          1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)

cluster_A::*>
----
. Asigne los discos Container.
+
Antes de asignar los discos, asegúrese de asignar la cantidad recomendada de unidades de repuesto a cada nodo. Estas unidades se crean particiones antes de migrar el agregado raíz. Para obtener más información, consulte link:https://docs.netapp.com/us-en/ontap-metrocluster/install-ip/concept_considerations_drive_assignment.html["Consideraciones sobre la asignación automática de unidades y los sistemas ADP en ONTAP 9.4 y versiones posteriores"].

+
Ejecute el siguiente comando para asignar los discos:

+
`storage disk assign -disklist 1.11.0,1.11.1,…  -owner cluster-01 -pool 0`

. Identifique el tamaño de la partición raíz.
+
El tamaño de la partición raíz depende del número de discos disponibles para la partición en cada nodo. NetApp recomienda que haya disponibles para la partición al menos 12 unidades por nodo.

+
Puede utilizar la siguiente tabla para determinar la distribución del agregado raíz:

+
[cols="25,75"]
|===
| Núm. De discos para particionar | Distribución del agregado raíz 


| 4 discos por nodo | 2 unidades de datos y 2 unidades de paridad 


| 12 discos por nodo | 8 unidades de datos, 2 unidades de paridad y 2 unidades de repuesto 


| 24 discos por nodo | 20 unidades de datos, 2 unidades de paridad y 2 unidades de repuesto 
|===
+
Para identificar el tamaño de la partición raíz, divida el número total de bloques de 4K KB de forma equitativa entre todas las unidades de datos.

+
Por ejemplo, si tiene una distribución de agregado raíz de 8 unidades de datos, 2 unidades de paridad y 2 unidades de repuesto con un tamaño de agregado raíz de 112958795 bloques, se debe dividir 112958795 entre 8 para obtener el tamaño de la partición raíz.

+
(112958795 / 8) = 14119849,375

+
Después de que esta figura se redondea hacia arriba, el tamaño de la partición raíz es 14119850.

. Cree una partición de cada disco del agregado raíz:
+
`cluster_A*> disk partition -n 3 -i 3 -b <root_partition_size> <disk_id>`

. Asigne las particiones.
+

NOTE: En los sistemas que utilizan ADP, los agregados se crean utilizando particiones en las que cada unidad se divide en particiones P1, P2 y P3.

+
.. Asigne la partición P3 al mismo nodo propietario del disco contenedor:
+
`storage disk assign -disk <disk_id> -root true -pool 0 -owner cluster-01`

.. Asigne la partición P1 al sistema con el número de ID de sistema inferior en el par de alta disponibilidad:
+
`storage disk assign -disk <disk_id> -data1 true -pool 0 -owner cluster-01`

.. Asigne la partición P2 al sistema con el número de ID de sistema superior en el par de alta disponibilidad:
+
`storage disk assign -disk <disk_name> -data2 true -pool 0 -owner cluster-02`

+
Repita este paso con cada disco particionado.



. Confirme que la toma de control es posible:
+
`storage failover show`

+
[listing]
----
cluster_A::> storage failover show
                              Takeover
Node           Partner        Possible State Description
-------------- -------------- -------- ---------------------------
cluster-01     cluster-02      true     Connected to cluster-02

cluster-02     cluster-01      true     Connected to cluster-01
2 entries were displayed.
----
. Migre el agregado raíz.
+
Para cada nodo, realice la migración especificando la lista de discos en Pool0 y el tipo de RAID de destino como parámetros:

+
`system node migrate-root -node cluster-01 -disklist <pool0_disk_list> -raid-type <target_raid_type>`

+
Por ejemplo, si el agregado raíz del «cluster-01» consta de diez discos con «raid_dp», el siguiente comando migra el agregado raíz:

+
[listing]
----
system node migrate-root -node cluster-01 -disklist 1.11.1.P3,1.11.2.P3,1.11.3.P3,1.11.4.P3,1.11.5.P3,1.11.6.P3,1.11.7.P3,1.11.8.P3,1.11.9.P3,1.11.10.P3 -raid-type raid_dp

Warning: This is a partially automated and guided procedure for migrating the
         root aggregate on the node "cluster-01".
         Negotiated switchover is about to start.
         Warning: This operation will create a new root aggregate and replace
         the existing root on the node "cluster-01". The existing root
         aggregate will be discarded.
Do you want to continue? {y|n}: y

Info: Started migrate-root job. Run "job show -id 51 -instance" command to
      check the progress of the job.
      Once the job is complete, mirror the root aggregate using the "storage
      aggregate mirror" command
----
+

IMPORTANT: Si el número de discos no es suficiente, añada más discos o elija un tipo de RAID diferente.

+
El proceso de migración puede tardar varios minutos en completarse. Durante la migración, el nodo se reinicia varias veces y es posible que vea errores en los otros nodos, puede ignorar de forma segura estos errores y esperar a que finalice el proceso de migración.

. Si lo desea, supervise el progreso de la migración.
+
Desde el segundo sitio, ejecute:

+
`job show -id 51 -instance`

. Vuelva a habilitar la creación de particiones automáticas de RAID para todos los nodos IP de MetroCluster:
+
`storage raidlm policy modify -node <node> -policy-name auto_partition_ssds_post_init -policy-type Shared-Disk -is-enable true`

. Verifique que la migración se ha realizado correctamente:
+
`run local aggr status -r <root_agg_name>`

+
[listing]
----
cluster_A::*> node run local aggr status -r <root_agg_name>
Aggregate <root_agg_name> (online, raid0, fast zeroed) (block checksums)
  Plex /<root_agg_name>/plex0 (online, normal, active, pool0)
    RAID group /<root_agg_name>/plex0/rg0 (normal, block checksums, max_wdbn 6127616)

      RAID Disk Device  HA  SHELF BAY CHAN Pool Type  RPM  Used (MB/blks)    Phys (MB/blks)
      --------- ------  ------------- ---- ---- ---- ----- --------------    --------------
      data      e2a.11.0.16P3   e2a   11  16  NV:A   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.17P3  e10b  11  17  NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)

cluster_A::*>
----
. Repita el paso a. <<step_1,compruebe el estado de la configuración>>.

